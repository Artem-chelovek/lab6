## Анализ алгоритма: Shell Sort

**Определение:**
Shell Sort — это алгоритм сортировки, который делает поэтапное упорядочивание элементов с помощью серии интервалов (gap). На каждом этапе сортируются элементы, находящиеся на расстоянии, равном текущему интервалу, что похоже на обобщение вставочной сортировки. После этого интервал уменьшается, пока не станет равен 1, когда выполняется окончательная вставочная сортировка.

**Анализ:**
- Алгоритм начинается с большого интервала, выполняет вставочную сортировку элементов, разделенных этим интервалом.
- Далее интервал уменьшается по заданной последовательности (например, делением на 2).
- Когда интервал равен 1, выполняется обычная вставочная сортировка, которая уже упорядочивает оставшиеся элементы.
- Внутренние операции похожи на вставочную сортировку с шагом равным текущему интервалу.

**Временная сложность:**
- **В худшем случае** время выполнения этого алгоритма — **O(n²)**.
- В этом случае, при неправильной последовательности интервалов, вставочная сортировка на каждом этапе может работать за квадратичное время из-за вложенного цикла `while` в цикл `for`, особенно при плохо подобранных интервалах, таких как последовательности, приводящие к сортировке почти в обратном порядке.



---

## Анализ алгоритма: Merge Sort

***Определение:***
Merge Sort — это рекурсивный алгоритм сортировки «разделяй и властвуй». Он делит массив на две половины, сортирует каждую рекурсивно и объединяет отсортированные половины в один отсортированный массив.

***Анализ:***

- Временная сложность определяется двумя основными процессами:
  1. Делением массива на две части (рекурсия).
  2. Объединением двух отсортированных частей в один отсортированный массив (слияние).

- На каждом уровне рекурсии массив делится пополам, и на каждом уровне происходит объединение элементов.

***Какие циклы влияют на временную сложность (в худшем случае)?***

**Основные циклы:**

1. **Рекурсивные вызовы:**  
   - На каждом уровне массива происходит деление, глубина рекурсии — \( \log_2 n \).

2. **Процесс слияния — цикл, объединяющий две отсортированные части:**  
   ```python
   i, j, k = 0, 0, 0
   while i < n1 and j < n2:
       if left[i] <= right[j]:
           merged[k] = left[i]
           i += 1
       else:
           merged[k] = right[j]
           j += 1
       k += 1
   ```
   - Внутренний цикл **выполняется один раз** для каждого уровня рекурсии, сравнивая и объединяя элементы двух массивов.
   - Общее число операций при объединении всех элементов — равно \( n \), так как каждый элемент добавляется ровно один раз.

**Важно:**  
- В каждом вызове функция слияния — это цикл, который проходит по всему массиву (или его части).
- В худшем случае, во время слияния и сравнения рассматривается вся входная последовательность один раз.

---

### Влияние циклов на временную сложность:

- Аргумент: на каждом уровне рекурсии происходит объединение двух частей, суммарно покрывающее весь массив.
- В худшем случае, каждый уровень выполняет слияние за \( O(n) \).

- Количество уровней рекурсии: \( \log_2 n \).

- **Общий в худшем случае времени:**

\[
O(n \log n)
\]

Это обусловлено тем, что на каждом уровне происходит объединение всего массива за \( O(n) \), а уровней примерно \( \log_2 n \).

---

### Итог:

- **Ключевой цикл, влияющий на временную сложность в худшем случае — цикл слияния, который осуществляется на каждом уровне рекурсии.**
- **Внутренний цикл слияния — самый важный цикл для оценки сложности**: он работает за \( O(n) \) на каждом уровне, а всего уровней — около \( \log n \).
- В итоге: **в худшем случае — O(n log n)**.

---

## Анализ алгоритма: Сортировка выбором (Selection Sort)

**Определение:**
Сортировка выбором — это алгоритм, который разделяет массив на две части: отсортированную и неотсортированную. На каждом шаге он ищет минимальный элемент среди неотсортированной части и меняет его местами с первым элементом этой части.

**Анализ:**

- Алгоритм последовательно находит минимальный элемент в неотсортированной части массива и меняет его местами с первым элементом этой части.
  
- Внешний цикл `for` выполняется **n-1 раз** (где n — длина массива).

- Внутренний цикл `for` в худшем случае выполняется:
  - В первый проход — n-1 сравнений
  - Во второй — n-2 сравнений
  - И так далее, до 1 сравнения в последней итерации.

- Общее количество сравнений примерно равно:  
  (n*(n-1))/2

- **Временная сложность:** **O(n²)**

- Почему O(n²):  
  Два вложенных цикла, где каждый из них в худшем случае зависит от n. Внутренний цикл может выполняться до n раз для каждого из n итераций внешнего цикла, что приводит к квадратичной зависимости.

---


Определение метода QuickSort:

QuickSort — это эффективный алгоритм сортировки, основанный на методе «разделяй и властвуй». Он работает путём рекурсивного разбиения массива на две части по выбранному опорному элементу (пивоту), так чтобы элементы, меньшие пивота, оказались слева, а большие — справа. После разделения алгоритм рекурсивно сортирует обе части, пока массивы не станут полностью отсортированными.

Основные шаги алгоритма:

1.Выбрать опорный элемент.
2.Переставить элементы так, чтобы слева оказались меньшие или равные пивоту, а справа — большие.
3.Рекурсивно применить тот же процесс к левому и правому подмассивам.

Лучший и средний случаи:
Если выбранный пивот разбивает массив примерно на две равные части, то глубина рекурсии будет логарифмической, а на каждом уровне происходит линейная работа по перераспределению элементов.

Путём решения этого уравнения, например, методом мастер-теоремы, получаем:
O(n*log(n))
​
Худший случай:
Если опорный элемент выбирается неправильно и делит массив неравномерно (например, на 0 и n-1 элементы), то на каждой итерации остаётся почти весь массив, и глубина рекурсии становится линейной.

Так как тут два вложенных цикла for то это даёт сложность:
O(n^2) 


В среднем и в лучшем случае, благодаря равномерному делению, алгоритм работает очень быстро — O(n*log(n)).
В худшем случае, при неудачном выборе пивота, он превращается в сортировку вставками или пузырьковой — с квадратичной сложностью O(n^2)
Итог:

Ситуация	Временная сложность
Лучший случай	O(n*log(n))
Средний случай	O(n*log(n))
Худший случай	O(n^2)

---

**Определение метода Insertion Sort (сортировка вставками):**

Insertion Sort — это простой алгоритм сортировки, основанный на последовательном построении отсортированной части массива. Он работает путём итеративного вставления каждого следующего элемента в уже отсортированную часть массива на правильную позицию, смещая остальные элементы при необходимости.



**Основные шаги алгоритма:**

1. Начинается с второго элемента массива (предполагается, что первый — уже отсортирован).
2. Для каждого элемента сравнивает его с элементами слева, пока не найдёт место для вставки.
3. Вставляет элемент в подходящую позицию, сдвигая оставшиеся элементы вправо.
4. Повторяет шаги для всех элементов массива.



**Анализ временной сложности Insertion Sort:**

- **Лучший случай:**

Если массив уже отсортирован или почти отсортирован, то внутри внешнего цикла сравнения практически не требуют перестановок, и алгоритм работает за линейное время.

- **Оценка:**

\[ T(n) = O(n) \]

поскольку проход по массиву и сравнения совершаются только один раз, без необходимости перемещать элементы.

- **Средний и худший случаи:**

Когда массив отсортирован в обратном порядке или случайным образом, нужно сдвигать элементы при каждом вставлении.

- В худшем случае, для каждого элемента требуется сравнить и переместить с каждым предыдущим элемент.

- **Оценка:**

\[ T(n) = O(n^2) \]

потому что внутренний цикл выполняется примерно 1, 2, ..., \( n-1 \) раз, то есть сумма арифметической прогрессии:

\[ 1 + 2 + \dots + (n-1) \approx \frac{n(n-1)}{2} = O(n^2) \]



**Почему именно такая оценка:**

- В худшем случае, каждый новый элемент сравнивается с уже отсортированными, и выполняется сдвиг элементов, что в совокупности даёт квадратичную сложность.
- В лучшем случае (уже отсортированный массив), сравнения и сдвиги не нужны, и алгоритм работает за \( O(n) \).



**Итоговая таблица сложности Insertion Sort:**

| Ситуация          | Временная сложность               |
||--|
| Лучший случай    | \( O(n) \)                      |
| Средний случай   | \( O(n^2) \)                    |
| Худший случай    | \( O(n^2) \)                    |



**Краткое резюме:**

Insertion Sort — хороший выбор для небольших или почти отсортированных массивов, так как он очень прост и при этом эффективен в этих случаях. Однако для больших или случайных массивов его эффективность уступает более сложным алгоритмам, таким как QuickSort или HeapSort.

---

## Анализ алгоритма: Bubble Sort

### Определение:
Bubble Sort — это простой алгоритм сортировки, в котором повторяющиеся проходы по массиву сравнивают соседние элементы и меняют их местами, если они расположены в неверном порядке. Этот процесс продолжается, пока массив не станет отсортирован.


### Анализ:

- В каждом проходе внешний цикл выполняется для многократных итераций по всему массиву.
- Внутренний цикл сравнивает соседние элементы и при необходимости меняет их местами.
- После каждого полного прохода наибольший элемент "всплывает" в конец массива, то есть его позиция становится на место.
- В худшем случае, массив изначально отсортирован в обратном порядке, и каждый проход требует сравнения и обмена для почти всех пар, что делает алгоритм очень медленным.


### Какие циклы влияют на временную сложность (в худшем случае)?

**Основные циклы:**

1. **Внешний цикл:**
```python
for i in range(n):
    # Внутренний цикл
```
- Выполняется приблизительно **n раз**.
- отвечает за количество проходов, необходимых для полного упорядочивания массива.

2. **Внутренний цикл:**
```python
for j in range(0, n - i - 1):
    if arr[j] > arr[j + 1]:
        # Перестановка
```
- В каждом проходе внешний цикл внутренний цикл сравнивает соседние элементы.
- В худшем случае, каждое сравнение приводит к обмену, и внутренний цикл выполняется почти \( n - i - 1 \) раз.

### Влияние циклов на временную сложность:

- **Общее количество сравнений и обменов** (в худшем случае) — сумма арифметической прогрессии:
  
  \[
  (n-1) + (n-2) + ... + 1 = n(n-1)/2
  \]
  
- **Основной фактор, влияющий на временную сложность**, — вложенные циклы:
  - Внешний цикл выполняется примерно \( n \) раз.
  - Внутренний цикл для каждого прохода выполняется примерно \( n \) раз (с уменьшающимися значениями, но в худшем случае — все равно порядка \( n \)).

- **Итоговая сложность в худшем случае:**  
  \[
  O(n^2)
  \]


### Итог:

- **Ключевой цикл, влияющий на худшую временную сложность, — это внешний цикл, внутри которого вложен внутренний цикл.**
- **Основная причина — два вложенных цикла, обеспечивающих сравнение и обмен элементов, что в худшем случае приводит к квадратичной временной сложности.**

---

Если понадобятся еще разъяснения или графики — скажите!
